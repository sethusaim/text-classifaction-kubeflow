{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EDA for Ecommerce Text Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"D:/ecommerce-text-classifaction/data/ecommerceDataset.csv\",names = ['label', 'description'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of records with missing values\n",
    "\n",
    "print(f\"Number of records with missing values : {len(df) - len(df.dropna())}\")\n",
    "\n",
    "print(f\"Number of duplicate records : {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the number of records with missing values are 1, it is safe to drop that record\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are duplicated records which provide no meaning, we can drop those records also\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Label Encoding the target cols \n",
    "\n",
    "label_dict = {'Electronics': 0, 'Household': 1, 'Books': 2, 'Clothing & Accessories': 3}\n",
    "\n",
    "df.replace({'label': label_dict}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset by label\n",
    "data_e = df[df['label'] == 0] # Electronics\n",
    "data_h = df[df['label'] == 1] # Household\n",
    "data_b = df[df['label'] == 2] # Books\n",
    "data_c = df[df['label'] == 3] # Clothing & Accessories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Class Frequencies\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "values = np.array([len(data_e), len(data_h), len(data_b), len(data_c)])\n",
    "\n",
    "labels = ['Electronics', 'Household', 'Books', 'Clothing & Accessories']\n",
    "\n",
    "plt.title(\"Comparision of class frequencies\")\n",
    "\n",
    "fig = plt.pie(x=values,labels=labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of characters in description\n",
    "\n",
    "data_e_char = data_e['description'].str.len()\n",
    "data_h_char = data_h['description'].str.len()\n",
    "data_b_char = data_b['description'].str.len()\n",
    "data_c_char = data_c['description'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (10, 8.4), sharey = False)\n",
    "\n",
    "sns.histplot(x = data_e_char, bins = 20, ax = ax[0, 0]).set_title('Class: Electronics')\n",
    "sns.histplot(x = data_h_char, bins = 20, ax = ax[0, 1]).set_title('Class: Household')\n",
    "sns.histplot(x = data_b_char, bins = 20, ax = ax[1, 0]).set_title('Class: Books')\n",
    "sns.histplot(x = data_c_char, bins = 20, ax = ax[1, 1]).set_title('Class: Clothing & Accessories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of number of words in description\n",
    "data_e_word = data_e['description'].str.split().map(lambda x: len(x))\n",
    "data_h_word = data_h['description'].str.split().map(lambda x: len(x))\n",
    "data_b_word = data_b['description'].str.split().map(lambda x: len(x))\n",
    "data_c_word = data_c['description'].str.split().map(lambda x: len(x))\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (10, 8.4), sharey = False)\n",
    "sns.histplot(x = data_e_word, bins = 20, ax = ax[0, 0]).set_title('Class: Electronics')\n",
    "sns.histplot(x = data_h_word, bins = 20, ax = ax[0, 1]).set_title('Class: Household')\n",
    "sns.histplot(x = data_b_word, bins = 20, ax = ax[1, 0]).set_title('Class: Books')\n",
    "sns.histplot(x = data_c_word, bins = 20, ax = ax[1, 1]).set_title('Class: Clothing & Accessories')\n",
    "\n",
    "fig.suptitle(\"Distribution of number of words in description\")\n",
    "for i in range(4):\n",
    "    ax[i // 2, i % 2].set_xlabel(\" \") if i // 2 == 0 else ax[i // 2, i % 2].set_xlabel(\"Number of words\")\n",
    "    if i % 2 != 0: ax[i // 2, i % 2].set_ylabel(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of average word-length in description\n",
    "data_e_avg = data_e['description'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n",
    "data_h_avg = data_h['description'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n",
    "data_b_avg = data_b['description'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n",
    "data_c_avg = data_c['description'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (10, 8.4), sharey = False)\n",
    "sns.histplot(x = data_e_avg, bins = 20, ax = ax[0, 0]).set_title('Class: Electronics')\n",
    "sns.histplot(x = data_h_avg, bins = 20, ax = ax[0, 1]).set_title('Class: Household')\n",
    "sns.histplot(x = data_b_avg, bins = 20, ax = ax[1, 0]).set_title('Class: Books')\n",
    "sns.histplot(x = data_c_avg, bins = 20, ax = ax[1, 1]).set_title('Class: Clothing & Accessories')\n",
    "\n",
    "fig.suptitle(\"Distribution of average word-length in description\")\n",
    "for i in range(4):\n",
    "    ax[i // 2, i % 2].set_xlabel(\" \") if i // 2 == 0 else ax[i // 2, i % 2].set_xlabel(\"Average word-length\")\n",
    "    if i % 2 != 0: ax[i // 2, i % 2].set_ylabel(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = df.drop('label',axis=1),df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "data_train = pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "X_val,X_test,y_val,y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=42)\n",
    "\n",
    "data_val = pd.concat([X_val,y_val],axis=1)\n",
    "\n",
    "data_test = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "# Comparison of sizes of training set, validation set and test set\n",
    "values = np.array([len(data_train), len(data_val), len(data_test)])\n",
    "\n",
    "labels = ['Training set', 'Validation Set', 'Test set']\n",
    "\n",
    "plt.title(\"Comparision of sizes of training,validation and test set\")\n",
    "\n",
    "plt.pie(x=values,labels=labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "\n",
    "remove_html = lambda text : re.compile(r'<.*?>').sub(r'',text)\n",
    "\n",
    "convert_to_lowercase = lambda text : text.lower()\n",
    "\n",
    "remove_whitespace = lambda text : text.strip()\n",
    "\n",
    "remove_punctuation = lambda text : text.translate(str.maketrans(\"\", \"\", string.punctuation.replace(\"'\", \"\")))\n",
    "\n",
    "remove_html = lambda text : re.compile(r'<.*?>').sub(r'',text)\n",
    "\n",
    "remove_emoji = lambda text : re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags = re.UNICODE).sub(r'',text)\n",
    "\n",
    "remove_http = lambda text : re.sub(r\"({})\".format(\"https?://\\S+|www\\.\\S+\"), \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing acronyms\n",
    "\n",
    "acronyms_dict = pd.read_json(\"english_acronyms.json\", typ = 'series')\n",
    "\n",
    "acronyms_df = pd.DataFrame(acronyms_dict.items(), columns = ['acronym', 'original']).head()\n",
    "\n",
    "acronyms_list = list(acronyms_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert contractions in text\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "regexp = RegexpTokenizer(\"[\\w']+\")\n",
    "\n",
    "def convert_acronyms(text):\n",
    "    words = []\n",
    "    \n",
    "    for word in regexp.tokenize(text):\n",
    "        if word in acronyms_list:\n",
    "            words = words + acronyms_dict[word].split()\n",
    "        else:\n",
    "            words = words + word.split()\n",
    "            \n",
    "    text_converted = \" \".join(words)\n",
    "    \n",
    "    return text_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Substitution of Contractions\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "contractions_dict = pd.read_json(\"english_contractions.json\", typ = 'series')\n",
    "\n",
    "df_contractions = pd.DataFrame(contractions_dict.items(), columns = ['contraction', 'original']).head()\n",
    "\n",
    "contractions_list = list(contractions_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_contractions(text):\n",
    "    words = []\n",
    "\n",
    "    for word in regexp.tokenize(text):\n",
    "        if word in contractions_list:\n",
    "            words = words + contractions_dict[word].split()\n",
    "\n",
    "        else:\n",
    "            words = words + word.split()\n",
    "    \n",
    "    text_converted = \" \".join(words)\n",
    "\n",
    "    return text_converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "addstops = [\"among\", \"onto\", \"shall\", \"thrice\", \"thus\", \"twice\", \"unto\", \"us\", \"would\"]\n",
    "\n",
    "all_stopwords = stops + addstops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing stop words\n",
    "remove_stopwords = lambda text : \" \".join([word for word in regexp.tokenize(text) if word not in all_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correcting spelling\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def pyspellchecker(text):\n",
    "    word_list = regexp.tokenize(text)\n",
    "    \n",
    "    word_list_corrected = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in spell.unknown(word_list):\n",
    "            word_corrected = spell.correction(word)\n",
    "    \n",
    "            if word_corrected == None:\n",
    "                word_list_corrected.append(word)\n",
    "    \n",
    "            else:\n",
    "                word_list_corrected.append(word_corrected)\n",
    "        else:\n",
    "            word_list_corrected.append(word)\n",
    "    \n",
    "    text_corrected = \" \".join(word_list_corrected)\n",
    "    \n",
    "    return text_corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Stemming\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "text_stemmer = lambda text: \" \".join([stemmer.stem(word) for word in regexp.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Lemmatization\n",
    "\n",
    "import spacy\n",
    "\n",
    "spacy_lemmatizer = spacy.load(\"en_core_web_sm\", disable = ['parser', 'ner'])\n",
    "\n",
    "text_lemmatizer = lambda text : \" \".join([token.lemma_ for token in spacy_lemmatizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing non alphabetic words\n",
    "\n",
    "discard_non_alpha = lambda text : \" \".join([word for word in regexp.tokenize(text) if word.isalpha()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retainment of revelant POS\n",
    "import nltk\n",
    "\n",
    "def keep_pos(text):\n",
    "    tokens = regexp.tokenize(text)\n",
    "    \n",
    "    tokens_tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    keep_tags = ['NN', 'NNS', 'NNP', 'NNPS', 'FW', 'PRP', 'PRPS', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WPS', 'WRB']\n",
    "    \n",
    "    keep_words = [x[0] for x in tokens_tagged if x[1] in keep_tags]\n",
    "    \n",
    "    return \" \".join(keep_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing additional stop words\n",
    "alphabets = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "prepositions = [\"about\", \"above\", \"across\", \"after\", \"against\", \"among\", \"around\", \"at\", \"before\", \"behind\", \"below\", \"beside\", \"between\", \"by\", \"down\", \"during\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"near\", \"of\", \"off\", \"on\", \"out\", \"over\", \"through\", \"to\", \"toward\", \"under\", \"up\", \"with\"]\n",
    "\n",
    "prepositions_less_common = [\"aboard\", \"along\", \"amid\", \"as\", \"beneath\", \"beyond\", \"but\", \"concerning\", \"considering\", \"despite\", \"except\", \"following\", \"like\", \"minus\", \"onto\", \"outside\", \"per\", \"plus\", \"regarding\", \"round\", \"since\", \"than\", \"till\", \"underneath\", \"unlike\", \"until\", \"upon\", \"versus\", \"via\", \"within\", \"without\"]\n",
    "\n",
    "coordinating_conjunctions = [\"and\", \"but\", \"for\", \"nor\", \"or\", \"so\", \"and\", \"yet\"]\n",
    "\n",
    "correlative_conjunctions = [\"both\", \"and\", \"either\", \"or\", \"neither\", \"nor\", \"not\", \"only\", \"but\", \"whether\", \"or\"]\n",
    "\n",
    "subordinating_conjunctions = [\"after\", \"although\", \"as\", \"as if\", \"as long as\", \"as much as\", \"as soon as\", \"as though\", \"because\", \"before\", \"by the time\", \"even if\", \"even though\", \"if\", \"in order that\", \"in case\", \"in the event that\", \"lest\", \"now that\", \"once\", \"only\", \"only if\", \"provided that\", \"since\", \"so\", \"supposing\", \"that\", \"than\", \"though\", \"till\", \"unless\", \"until\", \"when\", \"whenever\", \"where\", \"whereas\", \"wherever\", \"whether or not\", \"while\"]\n",
    "\n",
    "others = [\"茫\", \"氓\", \"矛\", \"没\", \"没陋m\", \"没贸\", \"没貌\", \"矛帽\", \"没陋re\", \"没陋ve\", \"没陋\", \"没陋s\", \"没贸we\"]\n",
    "\n",
    "additional_stops = alphabets + prepositions + prepositions_less_common + coordinating_conjunctions + correlative_conjunctions + subordinating_conjunctions + others\n",
    "\n",
    "remove_additional_stopwords = lambda text : \" \".join([word for word in regexp.tokenize(text) if word not in additional_stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    \n",
    "    text = remove_whitespace(text)\n",
    "    \n",
    "    text = re.sub('\\n' , '', text) # converting text to one line\n",
    "    \n",
    "    text = re.sub('\\[.*?\\]', '', text) # removing square brackets\n",
    "    \n",
    "    text = remove_http(text)\n",
    "    \n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    text = remove_html(text)\n",
    "    \n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    text = convert_acronyms(text)\n",
    "    \n",
    "    text = convert_contractions(text)\n",
    "    \n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    # text = pyspellchecker(text)\n",
    "    \n",
    "    text = text_lemmatizer(text) \n",
    "    \n",
    "    text = discard_non_alpha(text)\n",
    "    \n",
    "    text = keep_pos(text)\n",
    "    \n",
    "    text = remove_additional_stopwords(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"We'll combine all functions into 1 SINGLE FUNCTION  & apply on @product #descriptions https://en.wikipedia.org/wiki/Text_normalization\"\n",
    "print(\"Input: {}\".format(text))\n",
    "\n",
    "print(\"Output: {}\".format(text_normalizer(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the text_normalizer function on the product description\n",
    "\n",
    "data_train_norm, data_val_norm, data_test_norm = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "data_train_norm['normalized description'] = data_train['description'].apply(text_normalizer)\n",
    "data_val_norm['normalized description'] = data_val['description'].apply(text_normalizer)\n",
    "data_test_norm['normalized description'] = data_test['description'].apply(text_normalizer)\n",
    "\n",
    "data_train_norm['label'] = data_train['label']\n",
    "data_val_norm['label'] = data_val['label']\n",
    "data_test_norm['label'] = data_test['label']\n",
    "\n",
    "data_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "X_train_norm, y_train = data_train_norm['normalized description'].tolist(), data_train_norm['label'].tolist()\n",
    "\n",
    "X_val_norm, y_val = data_val_norm['normalized description'].tolist(), data_val_norm['label'].tolist()\n",
    "\n",
    "X_test_norm, y_test = data_test_norm['normalized description'].tolist(), data_test_norm['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TfidfVec = TfidfVectorizer(ngram_range = (1, 1))\n",
    "\n",
    "X_train_tfidf = TfidfVec.fit_transform(X_train_norm)\n",
    "\n",
    "X_val_tfidf = TfidfVec.transform(X_val_norm)\n",
    "\n",
    "X_test_tfidf = TfidfVec.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train models with TFIDF vectorization \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier,SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"KNN Classifier\",\n",
    "    \"Decision Tree\",\n",
    "    \"Linear SVM\",\n",
    "    \"Random Forest\",\n",
    "    \"SGD Classifier\",\n",
    "    \"Ridge Classifier\",\n",
    "    \"XGBoost\",\n",
    "    \"AdaBoost\",\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(max_iter = 1000),\n",
    "    KNeighborsClassifier(n_neighbors = 149, n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    RandomForestClassifier(n_estimators = 100),\n",
    "    SGDClassifier(loss = 'hinge'),\n",
    "    RidgeClassifier(),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "def score(X_train, y_train, X_val, y_val, names = names, models = models):\n",
    "    score_df, score_train, score_val = pd.DataFrame(), [], []\n",
    "    \n",
    "    x = time()\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        y_train_pred, y_val_pred = model.predict(X_train), model.predict(X_val)\n",
    "    \n",
    "        score_train.append(accuracy_score(y_train, y_train_pred))\n",
    "    \n",
    "        score_val.append(accuracy_score(y_val, y_val_pred))\n",
    "    \n",
    "    score_df[\"Classifier\"], score_df[\"Training accuracy\"], score_df[\"Validation accuracy\"] = names, score_train, score_val\n",
    "    \n",
    "    score_df.sort_values(by = 'Validation accuracy', ascending = False, inplace = True)\n",
    "    \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of baseline models\n",
    "score(X_train_tfidf, y_train, X_val_tfidf, y_val, names = names, models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm_classifier,param_grid=svm_params,verbose=3,cv=5,n_jobs=-1,scoring=\"accuracy\")\n",
    "\n",
    "svm_grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"SVM best params : {svm_grid.best_params_}\")\n",
    "\n",
    "print(f\"SVM best score : {svm_grid.best_score_}\")\n",
    "\n",
    "svm_classifier.set_params(**svm_grid.best_params_)\n",
    "\n",
    "best_model_tfidf, best_params_tfidf, best_score_tfidf = SVC(), svm_grid.best_params_, svm_grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "786e61aa4275cc3192f366f55b7b0b680e79526cf5813729beec02ee15d8da4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
